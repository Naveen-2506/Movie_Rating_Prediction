{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2601ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Predicting Audience Ratings: Full Pipeline with Explanation\n",
    "\n",
    "# ### Step 1: Import Libraries\n",
    "# Import necessary Python libraries for data manipulation, model training, evaluation, and visualization.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ### Step 2: Load the Dataset\n",
    "# Load the dataset from the provided Excel file and inspect its structure.\n",
    "file_path = 'Rotten_Tomatoes_Movies3.xls'  # Update if necessary\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Display basic information about the dataset to understand its structure and contents.\n",
    "data.info()\n",
    "print(data.head())\n",
    "\n",
    "# ### Step 3: Handle Missing Values\n",
    "# Check for missing values in the dataset and replace missing `audience_rating` values with `tomatometer_rating`.\n",
    "print(\"Missing values:\\n\", data.isnull().sum())\n",
    "data['audience_rating'].fillna(data['tomatometer_rating'], inplace=True)\n",
    "\n",
    "# ### Step 4: Define Target and Features\n",
    "# Separate the target variable (`audience_rating`) from the features.\n",
    "target = 'audience_rating'\n",
    "features = data.drop(columns=[target])\n",
    "target_data = data[target]\n",
    "\n",
    "# ### Step 5: Encode Categorical Variables\n",
    "# Encode categorical features using Label Encoding to convert them into numeric format.\n",
    "categorical_cols = features.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    features[col] = le.fit_transform(features[col])\n",
    "\n",
    "# ### Step 6: Scale Numerical Features\n",
    "# Standardize numerical features to ensure they are on the same scale.\n",
    "numerical_cols = features.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "features[numerical_cols] = scaler.fit_transform(features[numerical_cols])\n",
    "\n",
    "# ### Step 7: Split Data into Training and Testing Sets\n",
    "# Divide the dataset into training (80%) and testing (20%) sets to evaluate the model.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# ### Step 8: Define Models\n",
    "# Define multiple models to compare their performance. These include Linear Regression, Random Forest, and XGBoost.\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# ### Step 9: Train and Evaluate Models\n",
    "# Train each model, evaluate it using cross-validation, and calculate performance metrics on the test set.\n",
    "results = {}\n",
    "predictions_dict = {}\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('model', model)\n",
    "    ])\n",
    "    # Perform 5-fold cross-validation\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    predictions_dict[name] = predictions\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    results[name] = {'R²': r2, 'MSE': mse, 'MAE': mae}\n",
    "    \n",
    "    print(f\"{name} Performance:\")\n",
    "    print(f\"R²: {r2}, MSE: {mse}, MAE: {mae}\\n\")\n",
    "\n",
    "# ### Step 10: Compare Models\n",
    "# Identify the best-performing model based on R² score.\n",
    "best_model_name = max(results, key=lambda x: results[x]['R²'])\n",
    "best_model = models[best_model_name]\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "\n",
    "# ### Step 11: Visualize Model Comparisons\n",
    "# Compare model performances using bar charts.\n",
    "metrics_df = pd.DataFrame(results).T\n",
    "metrics_df = metrics_df.sort_values(by='R²', ascending=False)\n",
    "\n",
    "# Plot R² Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=metrics_df.index, y='R²', data=metrics_df, palette='viridis')\n",
    "plt.title('R² Scores by Model')\n",
    "plt.ylabel('R²')\n",
    "plt.xlabel('Model')\n",
    "plt.show()\n",
    "\n",
    "# Plot MSE Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=metrics_df.index, y='MSE', data=metrics_df, palette='viridis')\n",
    "plt.title('Mean Squared Error by Model')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Model')\n",
    "plt.show()\n",
    "\n",
    "# Plot MAE Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=metrics_df.index, y='MAE', data=metrics_df, palette='viridis')\n",
    "plt.title('Mean Absolute Error by Model')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Model')\n",
    "plt.show()\n",
    "\n",
    "# ### Step 12: Validate the Best Model\n",
    "# Test the best model on the test set and visualize its predictions against actual values.\n",
    "best_model.fit(X_train, y_train)\n",
    "best_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Scatter Plot of Predictions vs Actual Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, best_predictions, alpha=0.7, label='Predictions')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Ideal Fit')\n",
    "plt.xlabel('Actual Ratings')\n",
    "plt.ylabel('Predicted Ratings')\n",
    "plt.title(f'{best_model_name} Predictions vs Actuals')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ### Step 13: Save Predictions and Model\n",
    "# Save the predictions to a CSV file and the best model to a file for future use.\n",
    "output = pd.DataFrame({'Actual': y_test, 'Predicted': best_predictions})\n",
    "output.to_csv('predictions.csv', index=False)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "# ### Summary\n",
    "# This notebook demonstrates a full pipeline for predicting `audience_rating` using multiple models. Model performances are compared using metrics and visualizations, the best model is selected, and its predictions are validated. The predictions and trained model are saved for future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f9e225-bc25-4e18-ac20-7f92debee9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Predicting Audience Ratings: Full Pipeline with Explanation\n",
    "\n",
    "# ### Step 1: Import Libraries\n",
    "# Import necessary Python libraries for data manipulation, model training, evaluation, and visualization.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ### Step 2: Load the Dataset\n",
    "# Load the dataset from the provided Excel file and inspect its structure.\n",
    "file_path = 'Rotten_Tomatoes_Movies3.xls'  # Update if necessary\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Display basic information about the dataset to understand its structure and contents.\n",
    "data.info()\n",
    "print(data.head())\n",
    "\n",
    "# ### Step 3: Handle Missing Values\n",
    "# Check for missing values in the dataset and replace missing `audience_rating` values with `tomatometer_rating`.\n",
    "print(\"Missing values:\\n\", data.isnull().sum())\n",
    "data['audience_rating'].fillna(data['tomatometer_rating'], inplace=True)\n",
    "\n",
    "# ### Step 4: Define Target and Features\n",
    "# Separate the target variable (`audience_rating`) from the features.\n",
    "target = 'audience_rating'\n",
    "features = data.drop(columns=[target])\n",
    "target_data = data[target]\n",
    "\n",
    "# ### Step 5: Encode Categorical Variables\n",
    "# Encode categorical features using Label Encoding to convert them into numeric format.\n",
    "categorical_cols = features.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    features[col] = le.fit_transform(features[col])\n",
    "\n",
    "# ### Step 6: Scale Numerical Features\n",
    "# Standardize numerical features to ensure they are on the same scale.\n",
    "numerical_cols = features.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "features[numerical_cols] = scaler.fit_transform(features[numerical_cols])\n",
    "\n",
    "# ### Step 7: Split Data into Training and Testing Sets\n",
    "# Divide the dataset into training (80%) and testing (20%) sets to evaluate the model.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# ### Step 8: Define Models\n",
    "# Define multiple models to compare their performance. These include Linear Regression, Random Forest, Gradient Boosting, Support Vector Regressor, and XGBoost.\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'Support Vector Regressor': SVR(),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# ### Step 9: Train and Evaluate Models\n",
    "# Train each model, evaluate it using cross-validation, and calculate performance metrics on the test set.\n",
    "results = {}\n",
    "predictions_dict = {}\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('model', model)\n",
    "    ])\n",
    "    # Perform 5-fold cross-validation\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    predictions_dict[name] = predictions\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    results[name] = {'R²': r2, 'MSE': mse, 'MAE': mae}\n",
    "    \n",
    "    print(f\"{name} Performance:\")\n",
    "    print(f\"R²: {r2}, MSE: {mse}, MAE: {mae}\\n\")\n",
    "\n",
    "# ### Step 10: Compare Models\n",
    "# Identify the best-performing model based on R² score.\n",
    "best_model_name = max(results, key=lambda x: results[x]['R²'])\n",
    "best_model = models[best_model_name]\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "\n",
    "# ### Step 11: Visualize Model Comparisons\n",
    "# Compare model performances using bar charts.\n",
    "metrics_df = pd.DataFrame(results).T\n",
    "metrics_df = metrics_df.sort_values(by='R²', ascending=False)\n",
    "\n",
    "# Plot R² Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=metrics_df.index, y='R²', data=metrics_df, palette='viridis')\n",
    "plt.title('R² Scores by Model')\n",
    "plt.ylabel('R²')\n",
    "plt.xlabel('Model')\n",
    "plt.show()\n",
    "\n",
    "# Plot MSE Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=metrics_df.index, y='MSE', data=metrics_df, palette='viridis')\n",
    "plt.title('Mean Squared Error by Model')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Model')\n",
    "plt.show()\n",
    "\n",
    "# Plot MAE Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=metrics_df.index, y='MAE', data=metrics_df, palette='viridis')\n",
    "plt.title('Mean Absolute Error by Model')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Model')\n",
    "plt.show()\n",
    "\n",
    "# ### Step 12: Validate the Best Model\n",
    "# Test the best model on the test set and visualize its predictions against actual values.\n",
    "best_model.fit(X_train, y_train)\n",
    "best_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Scatter Plot of Predictions vs Actual Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, best_predictions, alpha=0.7, label='Predictions')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Ideal Fit')\n",
    "plt.xlabel('Actual Ratings')\n",
    "plt.ylabel('Predicted Ratings')\n",
    "plt.title(f'{best_model_name} Predictions vs Actuals')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ### Step 13: Save Predictions and Model\n",
    "# Save the predictions to a CSV file and the best model to a file for future use.\n",
    "output = pd.DataFrame({'Actual': y_test, 'Predicted': best_predictions})\n",
    "output.to_csv('predictions.csv', index=False)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "# ### Summary\n",
    "# This notebook demonstrates a full pipeline for predicting `audience_rating` using multiple models. Model performances are compared using metrics and visualizations, the best model is selected, and its predictions are validated. The predictions and trained model are saved for future use.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
